{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TZJbdARYjayA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import ast  # Pour convertir les chaînes d'annotations en liste\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le fichier CSV contenant les données\n",
        "data = pd.read_csv('coarse-and-fine-grained-ner-dataset (1).csv')\n",
        "\n",
        "# Afficher les premières lignes pour vérifier la structure\n",
        "print(data.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSdhkkQTkFfS",
        "outputId": "70668498-637e-49cc-9112-ed5862218c13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  \\\n",
            "0   grandes feuilles opposées, oblongues-elliptiq...   \n",
            "1   feuilles opposées, groupées à l'extrémité des...   \n",
            "2   feuilles opposées, obovées oblongues, arrondi...   \n",
            "3   arbustes  petites feuilles opposées, groupées...   \n",
            "4   arbustes  feuilles opposées ou alternes, obla...   \n",
            "\n",
            "                                      Organ Entities  \\\n",
            "0  ['bouton', 'pédicelle', 'corolle', 'tube', 'fe...   \n",
            "1  ['limbe', 'style', 'filets', 'rameaux', 'sépal...   \n",
            "2  ['corolle', 'limbe', 'ovaire', 'lobes', 'base'...   \n",
            "3  ['anthères', 'pétales', 'tube', 'feuilles', 's...   \n",
            "4  ['base', 'nervure', 'feuilles', 'arbustes', 'l...   \n",
            "\n",
            "                                 Descriptor Entities  \\\n",
            "0  ['fermée', 'pubes-cents', 'cunéiformes', 'vent...   \n",
            "1  ['elliptiques', '1 cm de longueur', 'extrorses...   \n",
            "2  ['cunéiforme', '10,5 mm de longueur', 'long', ...   \n",
            "3  ['secondaires', 'accusé', 'saillantes', 'apicu...   \n",
            "4  ['proéminente', 'décurrente', 'alternes', 'obl...   \n",
            "\n",
            "                           Coarse-grained Annotation  \\\n",
            "0  [(650, 661, 'DESCRIPTEUR'), (968, 977, 'DESCRI...   \n",
            "1  [(609, 618, 'DESCRIPTEUR'), (129, 144, 'DESCRI...   \n",
            "2  [(60, 64, 'ORGANE'), (196, 205, 'DESCRIPTEUR')...   \n",
            "3  [(949, 959, 'DESCRIPTEUR'), (88, 105, 'DESCRIP...   \n",
            "4  [(140, 150, 'DESCRIPTEUR'), (32, 40, 'DESCRIPT...   \n",
            "\n",
            "                             Fine-grained Annotation  \n",
            "0  [(650, 661, 'DESCRIPTEUR'), (395, 407, 'DISPOS...  \n",
            "1  [(609, 618, 'DESCRIPTEUR'), (73, 80, 'FORME'),...  \n",
            "2  [(60, 64, 'ORGANE'), (180, 187, 'ORGANE'), (11...  \n",
            "3  [(949, 959, 'DESCRIPTEUR'), (88, 105, 'DESCRIP...  \n",
            "4  [(42, 54, 'FORME'), (119, 129, 'FORME'), (1, 9...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Conversion des annotations et préparation des données\n",
        "tagged_sentences = []\n",
        "\n",
        "# Parcourir les lignes du DataFrame\n",
        "for index, row in data.iterrows():\n",
        "    text = row['Text']\n",
        "    annotations = row['Fine-grained Annotation']\n",
        "\n",
        "    # Convertir en liste de tuples en toute sécurité\n",
        "    try:\n",
        "        annotations = ast.literal_eval(annotations)\n",
        "    except (ValueError, SyntaxError):\n",
        "        print(f\"Erreur dans l'annotation à l'index {index}\")\n",
        "        continue\n",
        "\n",
        "    # Extraire les entités\n",
        "    entities = [(text[start:end], label) for start, end, label in annotations]\n",
        "    tagged_sentences.append((text, entities))\n",
        "\n",
        "# Afficher les premières phrases pour vérification\n",
        "for i in range(min(5, len(tagged_sentences))):\n",
        "    print(f\"Phrase {i+1}: {tagged_sentences[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5abT6oGkL30",
        "outputId": "43c7ac35-3933-43e7-e874-274bfe1f507e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phrase 1: (\" grandes feuilles opposées, oblongues-elliptiques ou obovées-elliptiques, arrondies au sommet, obtuses ou cunéiformes à la base  limbe glabre, mesurant jusqu'à 20 cm de longueur sur 12 cm de largeur  nervure médiane proéminente dessous, un peu saillante dessus  nervures secondaires, 5 à 10 paires, incurvées, réunies en arceaux assez loin de la marge, saillantes dessous, bien marquées dessus, anastomosées à un réseau de nervilles à grosses mailles irrégulières, finement saillant dessus  pétiole 5-20 mm  fleurs blanches fasciculées sur le vieux bois  pédicelle 4-6 mm, glabre ou légèrement pubescent  galice : 4 sépales (2 + 2) de 2,5 mm, un peu pubes-cents extérieurement  corolle à 8 lobes de 3 mm; tube 2 mm  ëtamines 8, insérées à la gorge; filets 3 mm  ovaire velu, à 4 loges, prolongé d'un long style glabre  dans le bouton la corolle, étroitement fermée, laisse poindre très apparemment le style  fruits inconnus  le spécimen type renferme une seule graine fusiforme non carénée, de 2 cm long, 0,6 large, 0,6 épaisseur, à cicatrice oblongue coupant toute la face ventrale, à bords crénelés\", [('pubes-cents', 'DESCRIPTEUR'), ('anastomosées', 'DISPOSITION'), ('sépales', 'ORGANE'), ('bords', 'ORGANE'), ('cicatrice', 'ORGANE'), ('incurvées', 'DESCRIPTEUR'), ('secondaires', 'POSITION'), ('obovées-elliptiques', 'DESCRIPTEUR'), ('blanches', 'COULEUR'), ('glabre', 'SURFACE'), ('glabre', 'SURFACE'), ('style', 'ORGANE'), ('fleurs', 'ORGANE'), ('bouton', 'ORGANE'), ('fruits', 'ORGANE'), ('12 cm de largeur', 'MESURE'), ('fermée', 'DESCRIPTEUR'), ('feuilles', 'ORGANE'), ('filets', 'ORGANE'), ('pubescent', 'SURFACE'), ('bois', 'ORGANE'), ('marge', 'ORGANE'), ('nervure', 'ORGANE'), ('fasciculées', 'DISPOSITION'), ('lobes', 'ORGANE'), ('limbe', 'ORGANE'), ('carénée', 'DESCRIPTEUR'), ('velu', 'SURFACE'), ('crénelés', 'STRUCTURE'), ('base', 'ORGANE'), ('saillante', 'SURFACE'), ('pédicelle', 'ORGANE'), ('proéminente', 'DESCRIPTEUR'), ('ovaire', 'ORGANE'), ('cunéiformes', 'FORME'), ('corolle', 'ORGANE'), ('graine', 'ORGANE'), ('glabre', 'SURFACE'), ('20 cm de longueur', 'MESURE'), ('oblongues-elliptiques', 'DESCRIPTEUR'), ('nervilles', 'ORGANE'), ('ventrale', 'DESCRIPTEUR'), ('tube', 'ORGANE'), ('opposées', 'DISPOSITION'), ('loges', 'ORGANE'), ('style', 'ORGANE'), ('réseau', 'ORGANE'), ('corolle', 'ORGANE'), ('insérées', 'DESCRIPTEUR'), ('pétiole', 'ORGANE'), ('obtuses', 'FORME'), ('fusiforme', 'FORME'), ('laisse', 'ORGANE')])\n",
            "Phrase 2: (\" feuilles opposées, groupées à l'extrémité des rameaux, ovées oblongues, obtuses au sommet et à la base, ± 8 cm de longueur et ± 3 cm de largeur  limbe coriace, glabre  nervure médiane saillante dessus  i 6 paires de nervures secondaires très ascendantes, effacées  pétiole court, 4-5 mm  petites fleurs blanches groupées en glomérules denses sur les vieux rameaux, subsessiles  pédicelles 2-3 mm, pubescents  galice à 4 sépales de 1,5-2 mm, un peu pubescents extérieurement  corolle à (5-) 6 (-8) pétales  lobes elliptiques longs de 2,5 mm ; 6 (-8) étamines insérées à la gorge ; filets env  4 mm ; anthères extrorses 1-1,5 mm, avec une petite touffe de poils au sommet  tube épais, court, long de 1-1,5 mm ovaire velu surmonté du style glabre; 3-4 loges  petits fruits obovoïdes, avec une pointe aiguë, dure, au sommet, 1 cm de longueur sur 0,5 cm de diamètre\", [('extrorses', 'DESCRIPTEUR'), ('obtuses', 'FORME'), ('anthères', 'ORGANE'), ('secondaires', 'POSITION'), ('glabre', 'SURFACE'), ('saillante', 'SURFACE'), ('style', 'ORGANE'), ('base', 'ORGANE'), ('8 cm de longueur', 'MESURE'), ('insérées', 'DESCRIPTEUR'), ('glomérules', 'ORGANE'), ('pétiole', 'ORGANE'), ('glabre', 'SURFACE'), ('pubescents', 'SURFACE'), ('pétales', 'ORGANE'), ('fruits', 'ORGANE'), ('nervure', 'ORGANE'), ('ovaire', 'ORGANE'), ('0,5 cm de diamètre', 'MESURE'), ('loges', 'ORGANE'), ('lobes', 'ORGANE'), ('pédicelles', 'ORGANE'), ('ascendantes', 'DESCRIPTEUR'), ('tube', 'ORGANE'), ('sépales', 'ORGANE'), ('limbe', 'ORGANE'), ('1 cm de longueur', 'MESURE'), ('3 cm de largeur', 'MESURE'), ('oblongues', 'FORME'), ('elliptiques', 'FORME'), ('velu', 'SURFACE'), ('pubescents', 'SURFACE'), ('étamines', 'ORGANE'), ('coriace', 'DESCRIPTEUR'), ('rameaux', 'ORGANE'), ('corolle', 'ORGANE'), ('poils', 'ORGANE'), ('blanches', 'COULEUR'), ('feuilles', 'ORGANE'), ('rameaux', 'ORGANE'), ('opposées', 'DISPOSITION'), ('fleurs', 'ORGANE'), ('filets', 'ORGANE')])\n",
            "Phrase 3: (' feuilles opposées, obovées oblongues, arrondies au sommet, base cunéiforme  limbe atteignant 6 cm de longueur et 3 cm de largeur, glabre en dessus; tomentum apprimé brun dessous  nervure médiane saillante dessous  nervures secondaires 5-6 paires, très ascendantes, effacées dessus, peu visibles sous le tomentum en dessous  pétiole court, ± 5 mm  fleurs longuement pédicellées  pédicelles 10-13 mm, pubescents  calice à 4 sépales de 2,5-3 mm, pubescents brun extérieurement  corolle jaune pâle à (7-) 10 lobes; lobes longs de 6 mm; tube aussi long, 6,5 mm  étamines (7-) 10  filets insérés à la gorge, dépassant les lobes de la corolle, env  10,5 mm de longueur; anthères 2,5 mm  pas de staminodes  pistil de 22-23 mm  ovaire velu terminé par un très long style grêle; 4 loges  fruit inconnu', [('base', 'ORGANE'), ('nervure', 'ORGANE'), ('3 cm de largeur', 'MESURE'), ('lobes', 'ORGANE'), ('glabre', 'SURFACE'), ('fleurs', 'ORGANE'), ('oblongues', 'FORME'), ('pubescents', 'SURFACE'), ('corolle', 'ORGANE'), ('lobes', 'ORGANE'), ('limbe', 'ORGANE'), ('pistil', 'ORGANE'), ('6 cm de longueur', 'MESURE'), ('long', 'DESCRIPTEUR'), ('pédicelles', 'ORGANE'), ('tomentum', 'ORGANE'), ('apprimé', 'DESCRIPTEUR'), ('loges', 'ORGANE'), ('long', 'DESCRIPTEUR'), ('tomentum', 'ORGANE'), ('lobes', 'ORGANE'), ('cunéiforme', 'FORME'), ('anthères', 'ORGANE'), ('sépales', 'ORGANE'), ('pétiole', 'ORGANE'), ('secondaires', 'POSITION'), ('calice', 'ORGANE'), ('style', 'ORGANE'), ('10,5 mm de longueur', 'MESURE'), ('visibles', 'DESCRIPTEUR'), ('jaune', 'COULEUR'), ('pubescents', 'SURFACE'), ('ascendantes', 'DESCRIPTEUR'), ('étamines', 'ORGANE'), ('tube', 'ORGANE'), ('filets', 'ORGANE'), ('corolle', 'ORGANE'), ('feuilles', 'ORGANE'), ('fruit', 'ORGANE'), ('saillante', 'SURFACE'), ('velu', 'SURFACE'), ('opposées', 'DISPOSITION'), ('staminodes', 'ORGANE'), ('insérés', 'DESCRIPTEUR'), ('ovaire', 'ORGANE')])\n",
            "Phrase 4: (' arbustes  petites feuilles opposées, groupées aux extrémités des rameaux, oblongues ou oblongues-obovées à sommet arrondi, à base obtuse ou cunéiforme  limbe glabre, coriace, à bords un peu enroulés, 2-5 cm sur 0,6-2 cm  nervure médiane saillante dessous  nervures secondaires ± 5 paires, réunies en arceaux, légèrement imprimées dessus, peu saillantes dessous  reticulum de nervilles peu accusé  pétiole env  1,5 mm  fleurs par 2-4 dans l\\'axe des feuilles ou des cicatrices des feuilles\"! pédi-celles filiformes, longs de 10-20 mm, glabres  calice : 4 sépales ovés de 2 mm, glabres ou presque  corolle infundibuliforme, à 6 (-8) lobes ovés de 5 min; tube 8 à 12 mm  ëtamines autant que de pétales, insérées vers le milieu du tube; filets filiformes longs de 11-18 mm; anthères extrorses, de 2 mm  ovaire velu à (3-) 4 loges, surmonté d\\'un style filiforme exsert de 12-20 mm, glabre  petits fruits ovoïdes de 1,5 cm, apiculés et surmontés du style persistant, glabres  pédoncules grêles de 1,5 cm environ  calice persistant à la base  une seule graine ovoïde 1-1,3 cm de longueur, 5 mm de diamètre, non albuminée  cicatrice ovée, ou oblongue, occupant toute la face ventrale, un peu bombée  jeunes plants à feuilles filiformes, rappelant celles de vlieiluma pini-folium, mais plus longues', [('persistant', 'DESCRIPTEUR'), ('oblongues-obovées', 'DESCRIPTEUR'), ('fleurs', 'ORGANE'), ('saillante', 'SURFACE'), ('nervure', 'ORGANE'), ('feuilles', 'ORGANE'), ('ventrale', 'DESCRIPTEUR'), ('5 mm de diamètre', 'MESURE'), ('opposées', 'DISPOSITION'), ('pédoncules', 'ORGANE'), ('extrorses', 'DESCRIPTEUR'), ('anthères', 'ORGANE'), ('feuilles', 'ORGANE'), ('feuilles', 'ORGANE'), ('coriace', 'DESCRIPTEUR'), ('apiculés', 'FORME'), ('obtuse', 'FORME'), ('ovoïdes', 'DESCRIPTEUR'), ('calice', 'ORGANE'), ('filiformes', 'FORME'), ('filiformes', 'FORME'), ('bords', 'ORGANE'), ('sépales', 'ORGANE'), ('enroulés', 'DESCRIPTEUR'), ('exsert', 'STRUCTURE'), ('albuminée', 'DESCRIPTEUR'), ('cicatrices', 'ORGANE'), ('rameaux', 'ORGANE'), ('filiformes', 'FORME'), ('axe', 'ORGANE'), ('velu', 'SURFACE'), ('infundibuliforme', 'FORME'), ('style', 'ORGANE'), ('graine', 'ORGANE'), ('nervilles', 'ORGANE'), ('ovaire', 'ORGANE'), ('saillantes', 'SURFACE'), ('glabre', 'SURFACE'), ('longues', 'DESCRIPTEUR'), ('lobes', 'ORGANE'), ('oblongues', 'FORME'), ('insérées', 'DESCRIPTEUR'), ('imprimées', 'SURFACE'), ('filiforme', 'FORME'), ('oblongues', 'FORME'), ('base', 'ORGANE'), ('corolle', 'ORGANE'), ('bombée', 'DESCRIPTEUR'), ('style', 'ORGANE'), ('tube', 'ORGANE'), ('loges', 'ORGANE'), ('accusé', 'DESCRIPTEUR'), ('cunéiforme', 'FORME'), ('fruits', 'ORGANE'), ('pétiole', 'ORGANE'), ('feuilles', 'ORGANE'), ('tube', 'ORGANE'), ('arbustes', 'ORGANE'), ('persistant', 'DESCRIPTEUR'), ('base', 'ORGANE'), ('calice', 'ORGANE'), ('limbe', 'ORGANE'), ('filets', 'ORGANE'), ('secondaires', 'POSITION'), ('glabre', 'SURFACE'), ('pétales', 'ORGANE')])\n",
            "Phrase 5: (' arbustes  feuilles opposées ou alternes, oblancéolées ou obovées de 2,3-4,8 cm par 0,8-1,8 cm, à sommet arrondi, base cunéiforme et un peu décurrente  limbe glabre, coriace  nervure médiane proéminente dessous', [('oblancéolées', 'FORME'), ('cunéiforme', 'FORME'), ('arbustes', 'ORGANE'), ('base', 'ORGANE'), ('opposées', 'DISPOSITION'), ('proéminente', 'DESCRIPTEUR'), ('alternes', 'DISPOSITION'), ('coriace', 'DESCRIPTEUR'), ('décurrente', 'DISPOSITION'), ('nervure', 'ORGANE'), ('limbe', 'ORGANE'), ('glabre', 'SURFACE'), ('feuilles', 'ORGANE')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser X et Y\n",
        "X, Y = [], []\n",
        "\n",
        "# Préparer les données avec ajout du tag \"OUT\" pour les mots non annotés\n",
        "for sentence in tagged_sentences:\n",
        "    text, entities = sentence\n",
        "    if not entities:  # Vérification si `entities` est vide\n",
        "        continue\n",
        "\n",
        "    # Initialiser une liste de mots et de tags\n",
        "    X_sentence = []\n",
        "    Y_sentence = []\n",
        "\n",
        "    # Ajouter les entités avec leurs tags\n",
        "    for word, label in entities:\n",
        "        X_sentence.append(word.lower())  # Ajouter le mot en minuscules\n",
        "        Y_sentence.append(label)  # Ajouter le tag correspondant\n",
        "\n",
        "    # Ajouter les mots non annotés avec le tag \"OUT\"\n",
        "    words = text.split()  # Diviser le texte en mots\n",
        "    for word in words:\n",
        "        if word.lower() not in [entity[0].lower() for entity in entities]:  # Si le mot n'est pas déjà dans les entités\n",
        "            X_sentence.append(word.lower())\n",
        "            Y_sentence.append(\"OUT\")  # Tag \"OUT\" pour les mots non annotés\n",
        "\n",
        "    X.append(X_sentence)\n",
        "    Y.append(Y_sentence)\n",
        "\n",
        "# Vérifier les résultats\n",
        "print(f\"Exemple de X : {X[:2]}\")\n",
        "print(f\"Exemple de Y : {Y[:2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cvo8H3vkMdv",
        "outputId": "9ec89a7a-b1ab-46a0-af39-e4f5937cd1ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemple de X : [['pubes-cents', 'anastomosées', 'sépales', 'bords', 'cicatrice', 'incurvées', 'secondaires', 'obovées-elliptiques', 'blanches', 'glabre', 'glabre', 'style', 'fleurs', 'bouton', 'fruits', '12 cm de largeur', 'fermée', 'feuilles', 'filets', 'pubescent', 'bois', 'marge', 'nervure', 'fasciculées', 'lobes', 'limbe', 'carénée', 'velu', 'crénelés', 'base', 'saillante', 'pédicelle', 'proéminente', 'ovaire', 'cunéiformes', 'corolle', 'graine', 'glabre', '20 cm de longueur', 'oblongues-elliptiques', 'nervilles', 'ventrale', 'tube', 'opposées', 'loges', 'style', 'réseau', 'corolle', 'insérées', 'pétiole', 'obtuses', 'fusiforme', 'laisse', 'grandes', 'opposées,', 'ou', 'obovées-elliptiques,', 'arrondies', 'au', 'sommet,', 'ou', 'à', 'la', 'glabre,', 'mesurant', \"jusqu'à\", '20', 'cm', 'de', 'longueur', 'sur', '12', 'cm', 'de', 'largeur', 'médiane', 'dessous,', 'un', 'peu', 'dessus', 'nervures', 'secondaires,', '5', 'à', '10', 'paires,', 'incurvées,', 'réunies', 'en', 'arceaux', 'assez', 'loin', 'de', 'la', 'marge,', 'saillantes', 'dessous,', 'bien', 'marquées', 'dessus,', 'à', 'un', 'de', 'à', 'grosses', 'mailles', 'irrégulières,', 'finement', 'saillant', 'dessus', '5-20', 'mm', 'sur', 'le', 'vieux', '4-6', 'mm,', 'ou', 'légèrement', 'galice', ':', '4', '(2', '+', '2)', 'de', '2,5', 'mm,', 'un', 'peu', 'extérieurement', 'à', '8', 'de', '3', 'mm;', '2', 'mm', 'ëtamines', '8,', 'à', 'la', 'gorge;', '3', 'mm', 'velu,', 'à', '4', 'loges,', 'prolongé', \"d'un\", 'long', 'dans', 'le', 'la', 'corolle,', 'étroitement', 'fermée,', 'poindre', 'très', 'apparemment', 'le', 'inconnus', 'le', 'spécimen', 'type', 'renferme', 'une', 'seule', 'non', 'carénée,', 'de', '2', 'cm', 'long,', '0,6', 'large,', '0,6', 'épaisseur,', 'à', 'oblongue', 'coupant', 'toute', 'la', 'face', 'ventrale,', 'à'], ['extrorses', 'obtuses', 'anthères', 'secondaires', 'glabre', 'saillante', 'style', 'base', '8 cm de longueur', 'insérées', 'glomérules', 'pétiole', 'glabre', 'pubescents', 'pétales', 'fruits', 'nervure', 'ovaire', '0,5 cm de diamètre', 'loges', 'lobes', 'pédicelles', 'ascendantes', 'tube', 'sépales', 'limbe', '1 cm de longueur', '3 cm de largeur', 'oblongues', 'elliptiques', 'velu', 'pubescents', 'étamines', 'coriace', 'rameaux', 'corolle', 'poils', 'blanches', 'feuilles', 'rameaux', 'opposées', 'fleurs', 'filets', 'opposées,', 'groupées', 'à', \"l'extrémité\", 'des', 'rameaux,', 'ovées', 'oblongues,', 'au', 'sommet', 'et', 'à', 'la', 'base,', '±', '8', 'cm', 'de', 'longueur', 'et', '±', '3', 'cm', 'de', 'largeur', 'coriace,', 'médiane', 'dessus', 'i', '6', 'paires', 'de', 'nervures', 'très', 'ascendantes,', 'effacées', 'court,', '4-5', 'mm', 'petites', 'groupées', 'en', 'denses', 'sur', 'les', 'vieux', 'rameaux,', 'subsessiles', '2-3', 'mm,', 'galice', 'à', '4', 'de', '1,5-2', 'mm,', 'un', 'peu', 'extérieurement', 'à', '(5-)', '6', '(-8)', 'longs', 'de', '2,5', 'mm', ';', '6', '(-8)', 'à', 'la', 'gorge', ';', 'env', '4', 'mm', ';', '1-1,5', 'mm,', 'avec', 'une', 'petite', 'touffe', 'de', 'au', 'sommet', 'épais,', 'court,', 'long', 'de', '1-1,5', 'mm', 'surmonté', 'du', 'glabre;', '3-4', 'petits', 'obovoïdes,', 'avec', 'une', 'pointe', 'aiguë,', 'dure,', 'au', 'sommet,', '1', 'cm', 'de', 'longueur', 'sur', '0,5', 'cm', 'de', 'diamètre']]\n",
            "Exemple de Y : [['DESCRIPTEUR', 'DISPOSITION', 'ORGANE', 'ORGANE', 'ORGANE', 'DESCRIPTEUR', 'POSITION', 'DESCRIPTEUR', 'COULEUR', 'SURFACE', 'SURFACE', 'ORGANE', 'ORGANE', 'ORGANE', 'ORGANE', 'MESURE', 'DESCRIPTEUR', 'ORGANE', 'ORGANE', 'SURFACE', 'ORGANE', 'ORGANE', 'ORGANE', 'DISPOSITION', 'ORGANE', 'ORGANE', 'DESCRIPTEUR', 'SURFACE', 'STRUCTURE', 'ORGANE', 'SURFACE', 'ORGANE', 'DESCRIPTEUR', 'ORGANE', 'FORME', 'ORGANE', 'ORGANE', 'SURFACE', 'MESURE', 'DESCRIPTEUR', 'ORGANE', 'DESCRIPTEUR', 'ORGANE', 'DISPOSITION', 'ORGANE', 'ORGANE', 'ORGANE', 'ORGANE', 'DESCRIPTEUR', 'ORGANE', 'FORME', 'FORME', 'ORGANE', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT'], ['DESCRIPTEUR', 'FORME', 'ORGANE', 'POSITION', 'SURFACE', 'SURFACE', 'ORGANE', 'ORGANE', 'MESURE', 'DESCRIPTEUR', 'ORGANE', 'ORGANE', 'SURFACE', 'SURFACE', 'ORGANE', 'ORGANE', 'ORGANE', 'ORGANE', 'MESURE', 'ORGANE', 'ORGANE', 'ORGANE', 'DESCRIPTEUR', 'ORGANE', 'ORGANE', 'ORGANE', 'MESURE', 'MESURE', 'FORME', 'FORME', 'SURFACE', 'SURFACE', 'ORGANE', 'DESCRIPTEUR', 'ORGANE', 'ORGANE', 'ORGANE', 'COULEUR', 'ORGANE', 'ORGANE', 'DISPOSITION', 'ORGANE', 'ORGANE', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer le vocabulaire et les tags\n",
        "vocab = {word.lower() for sentence in X for word in sentence}\n",
        "tags = {tag for sentence in Y for tag in sentence}\n",
        "\n",
        "# Ajouter le tag \"OUT\" dans les tags\n",
        "tags.add(\"OUT\")\n",
        "\n",
        "print(f\"Taille du vocabulaire : {len(vocab)}\")\n",
        "print(f\"Nombre total de tags : {len(tags)}\")\n",
        "print(f\"Tags disponibles : {tags}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCYI1p_JkQjL",
        "outputId": "5326fe41-bc9a-491f-ab02-5b7e68320946"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du vocabulaire : 13496\n",
            "Nombre total de tags : 11\n",
            "Tags disponibles : {'DISPOSITION', 'FORME', 'SURFACE', 'OUT', 'COULEUR', 'DESCRIPTEUR', 'MESURE', 'STRUCTURE', 'DEVELOPPEMENT', 'POSITION', 'ORGANE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer les dictionnaires\n",
        "word_to_ix = {word: idx for idx, word in enumerate(vocab, start=0)}\n",
        "tag_to_ix = {tag: idx for idx, tag in enumerate(tags, start=0)}\n",
        "\n",
        "# Ajouter le token <PAD>\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "word_to_ix[PAD_TOKEN] = len(word_to_ix)\n",
        "tag_to_ix[PAD_TOKEN] = len(tag_to_ix)\n",
        "\n",
        "# Vérifier les dictionnaires\n",
        "print(f\"Dictionnaire des mots : {list(word_to_ix.items())[:10]}...\")  # Afficher les 10 premiers\n",
        "print(f\"Dictionnaire des tags : {tag_to_ix}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0O7HM9yn05i",
        "outputId": "acbdae6f-bf5d-4fad-969d-aaff1f6e87c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionnaire des mots : [('30 cm de diamètre', 0), ('robuste,', 1), ('rou-', 2), ('6-30-flores,', 3), ('2,5-11,5', 4), ('fonctionnellement', 5), ('1 mm de largeur', 6), ('jonction', 7), ('100-180 mm de long', 8), (\"d'éta-mines\", 9)]...\n",
            "Dictionnaire des tags : {'DISPOSITION': 0, 'FORME': 1, 'SURFACE': 2, 'OUT': 3, 'COULEUR': 4, 'DESCRIPTEUR': 5, 'MESURE': 6, 'STRUCTURE': 7, 'DEVELOPPEMENT': 8, 'POSITION': 9, 'ORGANE': 10, '<PAD>': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Préparer les séquences pour le modèle\n",
        "def prepare_sequence(sequence, word_to_ix):\n",
        "    return torch.tensor(\n",
        "        [word_to_ix.get(word, word_to_ix[PAD_TOKEN]) for word in sequence],\n",
        "        dtype=torch.long\n",
        "    )\n",
        "\n",
        "def prepare_tag_sequence(tags, tag_to_ix):\n",
        "    return torch.tensor(\n",
        "        [tag_to_ix.get(tag, tag_to_ix[PAD_TOKEN]) for tag in tags],\n",
        "        dtype=torch.long\n",
        "    )\n"
      ],
      "metadata": {
        "id": "GHEbQ4vLkskV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SPLIT_SIZE = 0.2\n",
        "\n",
        "# Diviser l'ensemble complet de données en ensembles d'entraînement et de test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=SPLIT_SIZE, random_state=4)\n",
        "\n",
        "# Diviser les données d'entraînement en ensembles d'entraînement et de validation\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=SPLIT_SIZE, random_state=4)\n",
        "\n",
        "# Afficher le nombre d'exemples dans chaque ensemble\n",
        "print(\"TRAINING DATA\")\n",
        "print('Number of sequences: {}'.format(len(X_train)))\n",
        "print(\"-\"*50)\n",
        "print(\"TESTING DATA\")\n",
        "print('Number of sequences: {}'.format(len(X_test)))\n",
        "print(\"-\"*50)\n",
        "print(\"VALIDATION DATA\")\n",
        "print('Number of sequences: {}'.format(len(X_val)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vducSSZCkuPz",
        "outputId": "f515a16b-ece1-4296-a79c-d41214e83909"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "Number of sequences: 535\n",
            "--------------------------------------------------\n",
            "TESTING DATA\n",
            "Number of sequences: 168\n",
            "--------------------------------------------------\n",
            "VALIDATION DATA\n",
            "Number of sequences: 134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VanillaLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(VanillaLSTMCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # GATES\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        i_t = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev))\n",
        "        f_t = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev))\n",
        "        o_t = torch.sigmoid(self.Wxo(x) + self.Who(h_prev))\n",
        "        g_t = torch.tanh(self.Wxg(x) + self.Whg(h_prev))\n",
        "\n",
        "        c_t = f_t * c_prev + i_t * g_t\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n",
        "\n",
        "class POSTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=0.5):\n",
        "        super(POSTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Couche d'embedding\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Vanilla LSTM Cell (cellule personnalisée)\n",
        "        self.lstm_cell = VanillaLSTMCell(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        # Couche fully connected (FC) pour prédire les étiquettes\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        # Obtenir les embeddings\n",
        "        embeds = self.word_embeddings(sentence)  # Shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        batch_size, seq_len, _ = embeds.size()\n",
        "        h_t = torch.zeros(batch_size, self.hidden_dim, device=embeds.device)\n",
        "        c_t = torch.zeros(batch_size, self.hidden_dim, device=embeds.device)\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            h_t, c_t = self.lstm_cell(embeds[:, t, :], h_t, c_t)  # Utilisation de la cellule LSTM personnalisée\n",
        "            outputs.append(h_t)\n",
        "\n",
        "        # Stack outputs and apply dropout\n",
        "        outputs = torch.stack(outputs, dim=1)  # (batch_size, seq_len, hidden_dim)\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        logits = self.fc(outputs)  # (batch_size, seq_len, tagset_size)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "xNhygP2kkwI1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Convertir les données X et Y en tensores\n",
        "X_tensor = [prepare_sequence(sentence, word_to_ix) for sentence in X]\n",
        "Y_tensor = [prepare_tag_sequence(tags, tag_to_ix) for tags in Y]\n",
        "\n",
        "# Créer un DataLoader\n",
        "train_data = TensorDataset(torch.nn.utils.rnn.pad_sequence(X_tensor, batch_first=True, padding_value=word_to_ix[PAD_TOKEN]),\n",
        "                           torch.nn.utils.rnn.pad_sequence(Y_tensor, batch_first=True, padding_value=tag_to_ix[PAD_TOKEN]))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "OP7pjlLGeNi0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialiser les hyperparamètres\n",
        "embedding_dim = 64\n",
        "hidden_dim = 64\n",
        "vocab_size = len(word_to_ix)\n",
        "tagset_size = len(tag_to_ix)\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = POSTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_ix[PAD_TOKEN])  # Ignorer le padding dans la perte\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# If a GPU is available, it will use the GPU. Otherwise, it will use the CPU.\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "    # Envoyer les données sur le GPU (si disponible)\n",
        "    sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "# Entraînement\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Passer en mode entraînement\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "        # Envoyer les données sur le GPU (si disponible)\n",
        "        sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "        # Réinitialiser les gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passer les données dans le modèle\n",
        "        tag_scores = model(sentence)  # Shape: (batch_size, seq_len, tagset_size)\n",
        "\n",
        "        # Redimensionner tag_scores et tags pour CrossEntropyLoss\n",
        "        tag_scores = tag_scores.view(-1, tagset_size)  # (batch_size * seq_len, tagset_size)\n",
        "        tags = tags.view(-1)  # (batch_size * seq_len)\n",
        "\n",
        "        # Calculer la perte\n",
        "        loss = criterion(tag_scores, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Suivi de la perte\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predictions = torch.argmax(tag_scores, dim=1)  # Obtenir les indices des classes prédites\n",
        "        mask = tags != tag_to_ix[PAD_TOKEN]  # Ignorer les positions de padding\n",
        "        correct_predictions += (predictions[mask] == tags[mask]).sum().item()\n",
        "        total_predictions += mask.sum().item()\n",
        "\n",
        "    # Calcul de la perte moyenne et de l'accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Affichage des résultats pour chaque époque\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o42K79bokyVv",
        "outputId": "66ec76b5-2b70-4eeb-d5dd-8a63088dd0c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.0714, Accuracy: 0.5353\n",
            "Epoch 2/10, Loss: 0.8241, Accuracy: 0.7857\n",
            "Epoch 3/10, Loss: 0.5652, Accuracy: 0.8449\n",
            "Epoch 4/10, Loss: 0.4611, Accuracy: 0.8762\n",
            "Epoch 5/10, Loss: 0.4004, Accuracy: 0.8849\n",
            "Epoch 6/10, Loss: 0.3695, Accuracy: 0.8879\n",
            "Epoch 7/10, Loss: 0.3491, Accuracy: 0.8914\n",
            "Epoch 8/10, Loss: 0.3294, Accuracy: 0.8948\n",
            "Epoch 9/10, Loss: 0.3095, Accuracy: 0.9007\n",
            "Epoch 10/10, Loss: 0.2859, Accuracy: 0.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialiser les hyperparamètres\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word_to_ix)\n",
        "tagset_size = len(tag_to_ix)\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = POSTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_ix[PAD_TOKEN])  # Ignorer le padding dans la perte\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# If a GPU is available, it will use the GPU. Otherwise, it will use the CPU.\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "    # Envoyer les données sur le GPU (si disponible)\n",
        "    sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "# Entraînement\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Passer en mode entraînement\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "        # Envoyer les données sur le GPU (si disponible)\n",
        "        sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "        # Réinitialiser les gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passer les données dans le modèle\n",
        "        tag_scores = model(sentence)  # Shape: (batch_size, seq_len, tagset_size)\n",
        "\n",
        "        # Redimensionner tag_scores et tags pour CrossEntropyLoss\n",
        "        tag_scores = tag_scores.view(-1, tagset_size)  # (batch_size * seq_len, tagset_size)\n",
        "        tags = tags.view(-1)  # (batch_size * seq_len)\n",
        "\n",
        "        # Calculer la perte\n",
        "        loss = criterion(tag_scores, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Suivi de la perte\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predictions = torch.argmax(tag_scores, dim=1)  # Obtenir les indices des classes prédites\n",
        "        mask = tags != tag_to_ix[PAD_TOKEN]  # Ignorer les positions de padding\n",
        "        correct_predictions += (predictions[mask] == tags[mask]).sum().item()\n",
        "        total_predictions += mask.sum().item()\n",
        "\n",
        "    # Calcul de la perte moyenne et de l'accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Affichage des résultats pour chaque époque\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ezSZdlIIR6",
        "outputId": "19f8eef2-542b-43cb-e771-ec23ca5000c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.5132, Accuracy: 0.6870\n",
            "Epoch 2/10, Loss: 0.5578, Accuracy: 0.8507\n",
            "Epoch 3/10, Loss: 0.4153, Accuracy: 0.8827\n",
            "Epoch 4/10, Loss: 0.3522, Accuracy: 0.8895\n",
            "Epoch 5/10, Loss: 0.3223, Accuracy: 0.8951\n",
            "Epoch 6/10, Loss: 0.2923, Accuracy: 0.9067\n",
            "Epoch 7/10, Loss: 0.2610, Accuracy: 0.9207\n",
            "Epoch 8/10, Loss: 0.2288, Accuracy: 0.9316\n",
            "Epoch 9/10, Loss: 0.1988, Accuracy: 0.9430\n",
            "Epoch 10/10, Loss: 0.1775, Accuracy: 0.9517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialiser les hyperparamètres\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word_to_ix)\n",
        "tagset_size = len(tag_to_ix)\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = POSTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_ix[PAD_TOKEN])  # Ignorer le padding dans la perte\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# If a GPU is available, it will use the GPU. Otherwise, it will use the CPU.\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "    # Envoyer les données sur le GPU (si disponible)\n",
        "    sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "# Entraînement\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Passer en mode entraînement\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "        # Envoyer les données sur le GPU (si disponible)\n",
        "        sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "        # Réinitialiser les gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passer les données dans le modèle\n",
        "        tag_scores = model(sentence)  # Shape: (batch_size, seq_len, tagset_size)\n",
        "\n",
        "        # Redimensionner tag_scores et tags pour CrossEntropyLoss\n",
        "        tag_scores = tag_scores.view(-1, tagset_size)  # (batch_size * seq_len, tagset_size)\n",
        "        tags = tags.view(-1)  # (batch_size * seq_len)\n",
        "\n",
        "        # Calculer la perte\n",
        "        loss = criterion(tag_scores, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Suivi de la perte\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predictions = torch.argmax(tag_scores, dim=1)  # Obtenir les indices des classes prédites\n",
        "        mask = tags != tag_to_ix[PAD_TOKEN]  # Ignorer les positions de padding\n",
        "        correct_predictions += (predictions[mask] == tags[mask]).sum().item()\n",
        "        total_predictions += mask.sum().item()\n",
        "\n",
        "    # Calcul de la perte moyenne et de l'accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Affichage des résultats pour chaque époque\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ky10wcaciM",
        "outputId": "0657a328-2ad0-4187-9a80-7db5104b6b23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.4374, Accuracy: 0.6660\n",
            "Epoch 2/10, Loss: 0.5202, Accuracy: 0.8776\n",
            "Epoch 3/10, Loss: 0.3886, Accuracy: 0.8862\n",
            "Epoch 4/10, Loss: 0.3408, Accuracy: 0.8905\n",
            "Epoch 5/10, Loss: 0.3077, Accuracy: 0.8976\n",
            "Epoch 6/10, Loss: 0.2784, Accuracy: 0.9139\n",
            "Epoch 7/10, Loss: 0.2446, Accuracy: 0.9278\n",
            "Epoch 8/10, Loss: 0.2127, Accuracy: 0.9391\n",
            "Epoch 9/10, Loss: 0.1854, Accuracy: 0.9476\n",
            "Epoch 10/10, Loss: 0.1613, Accuracy: 0.9553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "# Prepare the test data (convert to tensors)\n",
        "X_test_tensor = [torch.tensor([word_to_ix.get(word, word_to_ix[PAD_TOKEN]) for word in sentence], dtype=torch.long) for sentence in X_test]\n",
        "Y_test_tensor = [torch.tensor([tag_to_ix[tag] for tag in tags], dtype=torch.long) for tags in Y_test]\n",
        "\n",
        "# Tester avec les données de test\n",
        "model.eval()  # Mettre le modèle en mode évaluation\n",
        "with torch.no_grad():\n",
        "    y_true = []  # Liste des vérités de terrain\n",
        "    y_pred = []  # Liste des prédictions du modèle\n",
        "    correct_predictions = 0  # Compteur des prédictions correctes\n",
        "    total_predictions = 0  # Compteur total des prédictions\n",
        "\n",
        "    for sentence, tags in zip(X_test_tensor, Y_test_tensor):\n",
        "        sentence_in = torch.tensor(sentence, dtype=torch.long).unsqueeze(0)  # Ajouter une dimension batch\n",
        "        tags_in = torch.tensor(tags, dtype=torch.long).unsqueeze(0)  # Ajouter une dimension batch\n",
        "\n",
        "        # Passer les données à travers le modèle\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Obtenir les prédictions\n",
        "        predicted = torch.argmax(tag_scores, dim=2)  # Supposons que la forme soit correcte\n",
        "\n",
        "        # Ajouter les résultats aux listes\n",
        "        y_true.extend(tags_in.cpu().numpy().flatten())  # Convertir en numpy et aplatir\n",
        "        y_pred.extend(predicted.cpu().numpy().flatten())  # Convertir en numpy et aplatir\n",
        "\n",
        "        # Calculer les prédictions correctes\n",
        "        correct_predictions += (predicted == tags_in).sum().item()  # Vérifier si les prédictions sont correctes\n",
        "        total_predictions += tags_in.size(1)  # Ajouter le nombre total de tokens dans le batch\n",
        "\n",
        "    # Convertir en numpy pour calculer les métriques\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calcul de l'accuracy globale\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Accuracy globale: {accuracy:.4f}\")\n",
        "\n",
        "    # Afficher les métriques classiques\n",
        "    print(f\"Précision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"Rappel: {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "\n",
        "# Afficher un rapport complet des métriques pour chaque classe\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = list(tag_to_ix.keys())\n",
        "target_names.remove(\"<PAD>\")  # Retirer le token <PAD> s'il est présent\n",
        "labels = sorted(list(set(y_true) | set(y_pred)))  # Récupérer les classes uniques\n",
        "\n",
        "print(classification_report(y_true, y_pred, labels=labels, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad5U8KZHmqtu",
        "outputId": "97dc0a61-4d5f-49be-b547-709a9c7af032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-eba0de651984>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sentence_in = torch.tensor(sentence, dtype=torch.long).unsqueeze(0)  # Ajouter une dimension batch\n",
            "<ipython-input-17-eba0de651984>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tags_in = torch.tensor(tags, dtype=torch.long).unsqueeze(0)  # Ajouter une dimension batch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy globale: 0.9575\n",
            "Précision: 0.9569\n",
            "Rappel: 0.9575\n",
            "F1-Score: 0.9522\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      SURFACE       0.92      0.75      0.82       448\n",
            "       MESURE       0.00      0.00      0.00       159\n",
            "     POSITION       0.95      0.80      0.87       147\n",
            "    STRUCTURE       0.90      0.05      0.10       176\n",
            "DEVELOPPEMENT       0.00      0.00      0.00         6\n",
            "      COULEUR       0.99      0.68      0.81       171\n",
            "       ORGANE       0.89      0.97      0.92      4157\n",
            "        FORME       0.81      0.70      0.75       722\n",
            "  DESCRIPTEUR       0.64      0.81      0.71      1498\n",
            "          OUT       1.00      1.00      1.00     25907\n",
            "  DISPOSITION       1.00      0.01      0.01       133\n",
            "\n",
            "     accuracy                           0.96     33524\n",
            "    macro avg       0.74      0.52      0.55     33524\n",
            " weighted avg       0.96      0.96      0.95     33524\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple de phrase à tester\n",
        "sentence = \"Des feuilles ovales \"\n",
        "\n",
        "# Tokeniser la phrase (en séparant par des espaces, ou en utilisant une autre méthode de tokenisation si nécessaire)\n",
        "tokens = sentence.lower().split()\n",
        "\n",
        "# Convertir les tokens en indices (en utilisant le dictionnaire `word_to_ix`)\n",
        "sentence_in = torch.tensor([word_to_ix.get(word, word_to_ix[PAD_TOKEN]) for word in tokens], dtype=torch.long).unsqueeze(0)  # Ajouter la dimension batch\n",
        "\n",
        "# Passer la phrase dans le modèle pour obtenir les scores des tags\n",
        "with torch.no_grad():\n",
        "    tag_scores = model(sentence_in)\n",
        "\n",
        "# Obtenir les tags prédits (la classe avec la probabilité maximale)\n",
        "predicted = torch.argmax(tag_scores, dim=2).squeeze().cpu().numpy()\n",
        "\n",
        "# Afficher les mots avec leurs tags prédits\n",
        "for word, tag_idx in zip(tokens, predicted):\n",
        "    tag = list(tag_to_ix.keys())[list(tag_to_ix.values()).index(tag_idx)]\n",
        "    print(f\"Mot: {word} - Tag Prédit: {tag}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wmSHU6umrQw",
        "outputId": "e641e595-0bce-4b8d-f3bc-e69594280bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mot: des - Tag Prédit: OUT\n",
            "Mot: feuilles - Tag Prédit: ORGANE\n",
            "Mot: ovales - Tag Prédit: FORME\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PeepholeLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(PeepholeLSTMCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # GATES\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wci = nn.Parameter(torch.randn(hidden_size))  # Peephole pour it\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wcf = nn.Parameter(torch.randn(hidden_size))  # Peephole pour ft\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wco = nn.Parameter(torch.randn(hidden_size))  # Peephole pour ot\n",
        "\n",
        "        # Candidate cell state\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        # Input gate\n",
        "        i_t = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev) + self.Wci * c_prev)\n",
        "\n",
        "        # Forget gate\n",
        "        f_t = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev) + self.Wcf * c_prev)\n",
        "\n",
        "        # Candidate cell state\n",
        "        g_t = torch.tanh(self.Wxg(x) + self.Whg(h_prev))\n",
        "\n",
        "        # Cell state\n",
        "        c_t = f_t * c_prev + i_t * g_t\n",
        "\n",
        "        # Output gate\n",
        "        o_t = torch.sigmoid(self.Wxo(x) + self.Who(h_prev) + self.Wco * c_t)\n",
        "\n",
        "        # Hidden state\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n"
      ],
      "metadata": {
        "id": "sCcNzm20Ra19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedPOSTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, dropout=0.5):\n",
        "        super(AdvancedPOSTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Couche d'embedding\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Peephole LSTM Cell (cellule personnalisée)\n",
        "        self.lstm_cell = PeepholeLSTMCell(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        # Couche fully connected (FC) pour prédire les étiquettes\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        # Obtenir les embeddings\n",
        "        embeds = self.word_embeddings(sentence)  # Shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        batch_size, seq_len, _ = embeds.size()\n",
        "        h_t = torch.zeros(batch_size, self.hidden_dim, device=embeds.device)\n",
        "        c_t = torch.zeros(batch_size, self.hidden_dim, device=embeds.device)\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            h_t, c_t = self.lstm_cell(embeds[:, t, :], h_t, c_t)  # Utilisation de la cellule LSTM personnalisée\n",
        "            outputs.append(h_t)\n",
        "\n",
        "        # Stack outputs and apply dropout\n",
        "        outputs = torch.stack(outputs, dim=1)  # (batch_size, seq_len, hidden_dim)\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        logits = self.fc(outputs)  # (batch_size, seq_len, tagset_size)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "sASj6gBZSZ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser les paramètres du modèle\n",
        "embedding_dim = 100  # Dimension des embeddings\n",
        "hidden_dim = 128     # Dimension cachée\n",
        "vocab_size = len(word_to_ix)  # Taille du vocabulaire\n",
        "tagset_size = len(tag_to_ix)  # Nombre de classes\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = AdvancedPOSTagger(\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    vocab_size=vocab_size,\n",
        "    tagset_size=tagset_size,\n",
        "    dropout=0.5\n",
        ").to(device)\n",
        "\n",
        "# Afficher la structure du modèle\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnyBWtcRSafB",
        "outputId": "f785907a-56cc-46dd-a41e-31fd89662fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdvancedPOSTagger(\n",
            "  (word_embeddings): Embedding(13497, 100)\n",
            "  (lstm_cell): PeepholeLSTMCell(\n",
            "    (Wxi): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (Whi): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (Wxf): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (Whf): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (Wxo): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (Who): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (Wxg): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (Whg): Linear(in_features=128, out_features=128, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=12, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialiser les hyperparamètres\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "vocab_size = len(word_to_ix)\n",
        "tagset_size = len(tag_to_ix)\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = AdvancedPOSTagger(embedding_dim, hidden_dim, vocab_size, tagset_size).to(device)  # Peephole LSTM\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_ix[PAD_TOKEN])  # Ignorer le padding dans la perte\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Entraînement\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Passer en mode entraînement\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch_idx, (sentence, tags) in enumerate(train_loader):\n",
        "        # Envoyer les données sur le GPU (si disponible)\n",
        "        sentence, tags = sentence.to(device), tags.to(device)\n",
        "\n",
        "        # Réinitialiser les gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passer les données dans le modèle\n",
        "        tag_scores = model(sentence)  # Shape: (batch_size, seq_len, tagset_size)\n",
        "\n",
        "        # Redimensionner tag_scores et tags pour CrossEntropyLoss\n",
        "        tag_scores = tag_scores.view(-1, tagset_size)  # (batch_size * seq_len, tagset_size)\n",
        "        tags = tags.view(-1)  # (batch_size * seq_len)\n",
        "\n",
        "        # Calculer la perte\n",
        "        loss = criterion(tag_scores, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Suivi de la perte\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calcul de la précision\n",
        "        predictions = torch.argmax(tag_scores, dim=1)  # Obtenir les indices des classes prédites\n",
        "        mask = tags != tag_to_ix[PAD_TOKEN]  # Ignorer les positions de padding\n",
        "        correct_predictions += (predictions[mask] == tags[mask]).sum().item()\n",
        "        total_predictions += mask.sum().item()\n",
        "\n",
        "    # Calcul de la perte moyenne et de l'accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Affichage des résultats pour chaque époque\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlAOy07aSdhP",
        "outputId": "212595f8-320f-4856-9694-19023a607e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.6601, Accuracy: 0.6344\n",
            "Epoch 2/10, Loss: 0.5855, Accuracy: 0.8359\n",
            "Epoch 3/10, Loss: 0.4050, Accuracy: 0.8820\n",
            "Epoch 4/10, Loss: 0.3600, Accuracy: 0.8878\n",
            "Epoch 5/10, Loss: 0.3371, Accuracy: 0.8940\n",
            "Epoch 6/10, Loss: 0.3228, Accuracy: 0.8980\n",
            "Epoch 7/10, Loss: 0.2849, Accuracy: 0.9105\n",
            "Epoch 8/10, Loss: 0.2594, Accuracy: 0.9220\n",
            "Epoch 9/10, Loss: 0.2330, Accuracy: 0.9319\n",
            "Epoch 10/10, Loss: 0.2086, Accuracy: 0.9403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Préparer les données de test (convertir en tenseurs)\n",
        "X_test_tensor = [torch.tensor([word_to_ix.get(word, word_to_ix[PAD_TOKEN]) for word in sentence], dtype=torch.long) for sentence in X_test]\n",
        "Y_test_tensor = [torch.tensor([tag_to_ix[tag] for tag in tags], dtype=torch.long) for tags in Y_test]\n",
        "\n",
        "# Mettre le modèle en mode évaluation\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_true = []  # Liste des vérités terrain\n",
        "    y_pred = []  # Liste des prédictions du modèle\n",
        "    correct_predictions = 0  # Compteur des prédictions correctes\n",
        "    total_predictions = 0  # Compteur total des prédictions\n",
        "\n",
        "    for sentence, tags in zip(X_test_tensor, Y_test_tensor):\n",
        "        # Convertir la phrase et les étiquettes en batch\n",
        "        sentence_in = sentence.unsqueeze(0).to(device)  # Ajouter une dimension batch et déplacer sur GPU si disponible\n",
        "        tags_in = tags.unsqueeze(0).to(device)  # Ajouter une dimension batch et déplacer sur GPU si disponible\n",
        "\n",
        "        # Passer la phrase dans le modèle\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Obtenir les prédictions\n",
        "        predicted = torch.argmax(tag_scores, dim=2).squeeze(0).cpu().numpy()  # Supprimer la dimension batch pour obtenir les prédictions\n",
        "\n",
        "        # Ajouter les prédictions et les vérités terrain aux listes\n",
        "        y_true.extend(tags.cpu().numpy().flatten())  # Convertir en numpy et aplatir\n",
        "        y_pred.extend(predicted.flatten())  # Aplatir les prédictions\n",
        "\n",
        "        # Calculer les prédictions correctes\n",
        "        correct_predictions += (predicted == tags.cpu().numpy()).sum()  # Comparer les prédictions avec les vérités terrain\n",
        "        total_predictions += tags.size(0)  # Ajouter le nombre de tokens dans la phrase\n",
        "\n",
        "    # Convertir les listes en numpy\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calcul de l'accuracy globale\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Accuracy globale: {accuracy:.4f}\")\n",
        "\n",
        "    # Afficher les métriques classiques\n",
        "    print(f\"Précision: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"Rappel: {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
        "\n",
        "# Afficher un rapport complet des métriques pour chaque classe\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = list(tag_to_ix.keys())\n",
        "target_names.remove(PAD_TOKEN)  # Retirer le token de padding\n",
        "labels = sorted(list(set(y_true) | set(y_pred)))  # Récupérer les classes uniques\n",
        "\n",
        "print(classification_report(y_true, y_pred, labels=labels, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEQ58b3ibAxg",
        "outputId": "a388a9a3-01ff-44c7-be03-87f5d555f847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy globale: 0.9492\n",
            "Précision: 0.9511\n",
            "Rappel: 0.9492\n",
            "F1-Score: 0.9422\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      SURFACE       0.92      0.71      0.80       448\n",
            "       MESURE       0.00      0.00      0.00       159\n",
            "     POSITION       1.00      0.52      0.68       147\n",
            "    STRUCTURE       1.00      0.01      0.01       176\n",
            "DEVELOPPEMENT       0.00      0.00      0.00         6\n",
            "      COULEUR       1.00      0.26      0.42       171\n",
            "       ORGANE       0.85      0.97      0.91      4157\n",
            "        FORME       0.77      0.49      0.60       722\n",
            "  DESCRIPTEUR       0.59      0.80      0.68      1498\n",
            "          OUT       1.00      1.00      1.00     25907\n",
            "  DISPOSITION       1.00      0.01      0.01       133\n",
            "\n",
            "     accuracy                           0.95     33524\n",
            "    macro avg       0.74      0.43      0.46     33524\n",
            " weighted avg       0.95      0.95      0.94     33524\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LvDVc8ObDaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
